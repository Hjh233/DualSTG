{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arcene.mat',\n",
       " 'BASEHOCK.mat',\n",
       " 'COIL20.mat',\n",
       " 'gisette.mat',\n",
       " 'Isolet.mat',\n",
       " 'madelon.mat',\n",
       " 'PCMAC.mat',\n",
       " 'RELATHE.mat']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "DIR = \"Data\"\n",
    "file_names = os.listdir(DIR)\n",
    "file_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arcene.mat (200, 10000) (200,)\n",
      "arcene\n",
      "Inserting : 0 Random Samples, 0 Overwhelmed Samples, 0 Shortcut Samples\n",
      "Client 0: Feature Index 0-2499\n",
      "Client 1: Feature Index 2500-4999\n",
      "Client 2: Feature Index 5000-7499\n",
      "Server : Feature Index 7500-9999\n",
      "[1 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0\n",
      " 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 0 0 1\n",
      " 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1\n",
      " 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1\n",
      " 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0]\n",
      "BASEHOCK.mat (1993, 4862) (1993,)\n",
      "BASEHOCK\n",
      "Inserting : 0 Random Samples, 0 Overwhelmed Samples, 0 Shortcut Samples\n",
      "Client 0: Feature Index 0-1215\n",
      "Client 1: Feature Index 1216-2431\n",
      "Client 2: Feature Index 2432-3646\n",
      "Server : Feature Index 3647-4861\n",
      "[0 0 0 ... 1 1 1]\n",
      "COIL20.mat (1440, 1024) (1440,)\n",
      "COIL20\n",
      "Inserting : 0 Random Samples, 0 Overwhelmed Samples, 0 Shortcut Samples\n",
      "Client 0: Feature Index 0-255\n",
      "Client 1: Feature Index 256-511\n",
      "Client 2: Feature Index 512-767\n",
      "Server : Feature Index 768-1023\n",
      "[ 1  1  1 ... 20 20 20]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HONGYI~1\\AppData\\Local\\Temp/ipykernel_11380/4292676670.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m                     \u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                     activation='relu')\n\u001b[1;32m---> 84\u001b[1;33m                 VFL.train(\n\u001b[0m\u001b[0;32m     85\u001b[0m                     \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\HONGYI001\\Desktop\\STG\\VFL.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(models, top_model, train_loader, val_loader, test_loader, criterion, optimizer, lr, epochs, freeze_btm_till, freeze_top_till, verbose, save_dir, log_dir, save_mask_at, mask_dir, early_stopping, patience, noise_label)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0membs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtop_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDualSTGModel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTGEmbModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2844\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2846\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from scipy.sparse import issparse\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from Data import VFLDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import VFL\n",
    "import torch\n",
    "for file_name in file_names:\n",
    "    if file_name.endswith(\".mat\"):\n",
    "        mat = loadmat(os.path.join(DIR, file_name))\n",
    "        X = mat[\"X\"]\n",
    "        y = mat[\"Y\"]\n",
    "        if issparse(X):\n",
    "                data_X = data_X.todense()\n",
    "        y = y.flatten()\n",
    "        print(file_name, X.shape, y.shape)\n",
    "        if file_name in ['madelon.mat', 'arcene.mat', 'gisette.mat']:\n",
    "            y[np.where(y == -1)] = 0\n",
    "        if file_name in ['BASEHOCK.mat', 'RELATHE.mat', 'PCMAC.mat']:\n",
    "            y[np.where(y == 1)] = 0\n",
    "            y[np.where(y == 2)] = 1\n",
    "        scaler = MinMaxScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        name = file_name.rstrip('.mat')\n",
    "        print(name)\n",
    "        RESULT_DIR = \"Results\"\n",
    "        result_dir = os.path.join(RESULT_DIR, name)\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.mkdir(result_dir)\n",
    "\n",
    "        EPOCH = 100\n",
    "        NUM_TRAIL = 5\n",
    "        NUM_NORMAL = np.arange(0, 100, 5)\n",
    "        NUM_OVERWHELMED = [0]+[5]*(len(NUM_NORMAL)-1)\n",
    "\n",
    "        NUM_SHORTCUT = [0, 1, 2, 3]\n",
    "        NUM_SHORTCUT = np.repeat(np.array(NUM_SHORTCUT), 5)\n",
    "        assert len(NUM_NORMAL) == len(NUM_OVERWHELMED) == len(NUM_SHORTCUT)\n",
    "\n",
    "        for trail in range(NUM_TRAIL):\n",
    "            for i, num_normal in enumerate(NUM_NORMAL):\n",
    "                num_over = NUM_OVERWHELMED[i]\n",
    "                num_shortcut = NUM_SHORTCUT[i]\n",
    "\n",
    "                dataset = VFLDataset(data_source=(X, y), \n",
    "                    num_clients=3,\n",
    "                    gini_portion=None,\n",
    "                    insert_noise=True, \n",
    "                    num_random_samples=num_normal,\n",
    "                    num_shortcut=num_shortcut,\n",
    "                    num_overwhelemd=num_over)\n",
    "\n",
    "                \n",
    "                train_loader = DataLoader(\n",
    "                    dataset.train(), batch_size=128, shuffle=True)\n",
    "                val_loader = DataLoader(\n",
    "                    dataset.valid(), batch_size=1000, shuffle=True)\n",
    "                test_loader = DataLoader(dataset.test(), batch_size=1000, shuffle=True)\n",
    "                input_dim_list = dataset.get_input_dim_list()\n",
    "                noisy_label = dataset.get_inserted_features_label()\n",
    "\n",
    "                print(y)\n",
    "\n",
    "                ###########################\n",
    "                # FNN Model\n",
    "                ############################\n",
    "\n",
    "                saving_name = f'FNN_Name_{name}_Trail_{trail}_Normal_{num_normal}_Overwhelmed_{num_over}_Shortcut_{num_shortcut}'\n",
    "                if np.unique(y).size == 2:\n",
    "                    output_dim = 1\n",
    "                    criterion = torch.nn.BCELoss()\n",
    "                else:\n",
    "                    output_dim = np.unique(y).size\n",
    "                    criterion = torch.nn.CrossEntropyLoss()\n",
    "                \n",
    "                type = \"FNN\" \n",
    "                models, top_model = VFL.make_binary_models(\n",
    "                    input_dim_list=input_dim_list, \n",
    "                    type=type, \n",
    "                    emb_dim=128, \n",
    "                    output_dim=output_dim, hidden_dims=[256, 128],\n",
    "                    activation='relu')\n",
    "                VFL.train(\n",
    "                    models, top_model, train_loader, val_loader, test_loader,\n",
    "                    epochs=EPOCH, \n",
    "                    criterion=criterion,\n",
    "                    verbose=False,\n",
    "                    save_dir=os.path.join(result_dir, saving_name)+\".pt\",\n",
    "                    log_dir=os.path.join(result_dir, saving_name)+\".csv\",\n",
    "                    save_mask_at=100000\n",
    "                )\n",
    "\n",
    "                ###########################\n",
    "                # STG Model\n",
    "                ############################\n",
    "                type = 'STG'\n",
    "                saving_name = f'STG_Name_{name}_Trail_{trail}_Normal_{num_normal}_Overwhelmed_{num_over}_Shortcut_{num_shortcut}'\n",
    "                models, top_model = VFL.make_binary_models(\n",
    "                    input_dim_list=input_dim_list,\n",
    "                    type='STG',\n",
    "                    emb_dim=128,\n",
    "                    output_dim=output_dim, hidden_dims=[256, 128],\n",
    "                    activation='relu')\n",
    "               \n",
    "                VFL.train(\n",
    "                    models, top_model, train_loader, val_loader, test_loader,\n",
    "                    epochs=EPOCH,\n",
    "                    criterion=criterion,\n",
    "                    verbose=False,\n",
    "                    save_dir=os.path.join(result_dir, saving_name)+\".pt\",\n",
    "                    log_dir=os.path.join(result_dir, saving_name)+\".csv\",\n",
    "                    save_mask_at=100000\n",
    "                )\n",
    "\n",
    "\n",
    "                ###########################\n",
    "                # Dual-STG Model\n",
    "                ###########################\n",
    "                type = 'Dual-STG'\n",
    "\n",
    "\n",
    "                break \n",
    "            break\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 1024) torch.Size([3, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HONGYI~1\\AppData\\Local\\Temp/ipykernel_11380/2999287490.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[0;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VFL\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   2844\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2846\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "x = torch.randn(3, 5)\n",
    "y = torch.tensor([1, 2, 3]).reshape(-1, 1)\n",
    "print(X.shape, y.shape)\n",
    "criterion(x,y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1579d4a348c2ef16482c05d3cfac916f73c8945ddf1938a1e045b3bdea82eece"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('VFL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
